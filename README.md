# trustworthy_ai_fields
A summary of current trustworthy AI research fields.

## Model Security
- Adversarial examples
  - adversarial attacks
    - white-box
      - Fast Gradient Signed Method (FGSM)
      - Projected Gradient Descent (PGD)
      - C&W
    - gray-box
    - black-box
      - one-pixel
  - adversarial defense
    - adversarial training
    - certified training
    - automated certification
    - image filter
    - randomness
    - anomaly detection

## Model Privacy
- Model stealing
  - defense
    - watermark
    - homomorphic encryption

## ML System/infrastructure Security
- Byzantine Learning
  - attacks
    - white-box
      - Reinforcement Learning
      - dynamic programming
    - gray-box
      - A Little Is Enough
      - Inner Product Manipulation
      - Sign-flipping
      - MinMax/MinSum
      - AGR-tailored attacks
      - mimic
    - white-box
      - Bit-flipping
      - Label-flipping
      - Random
      - 0
  - defenses
    - Pre-aggregation
      - Nearest-Neighbor-Mixing
      - Bucketing
      - Gradient Splitting
    - robust aggregation
      - Geometric Median
      - Coordinate-wise Median
      - Trimmed Mean
      - Krum
      - Centered Clipping
    - Certification
      - Zero-knowledge proof
      - Secure Multi-party Computation
      - Multi-party Homomorphic Encryption

## Data Security/Privacy
- Training data security/privacy
  - attacks
    - directly obtained
    - membership inference
    - gradient inversion
  - defenses
    - differential privacy
    - collaborative learning
    - homomorphic encryption

## Fairness

## Content Security
- Deep Fake Generation/Editting
- Intellectual Property
- Hateful Content Generation
